{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functionalities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modeling\n",
    "from gensim import matutils, models\n",
    "from gensim.models import LsiModel\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LDA_model(data_matrix, vectorizer, num_topics=4, passes=500):\n",
    "    # df --> sparse matrix --> gensim corpus\n",
    "    sparse_counts = scipy.sparse.csr_matrix(data_matrix)\n",
    "    gensim_corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "    id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "    lda = models.LdaModel(corpus=gensim_corpus, id2word=id2word, num_topics=num_topics, passes=passes)\n",
    "    \n",
    "    corpus_transformed = lda[gensim_corpus]\n",
    "    result = list(zip([max(ct, key=lambda x: x[1])[0] for ct in corpus_transformed], data_matrix.columns))\n",
    "    return lda, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all matrices\n",
    "clean_corpus_dtm = pd.read_pickle('./pickles/corpus0_dtm.pkl')\n",
    "clean_corpus_tim = pd.read_pickle('./pickles/corpus0_tim.pkl')\n",
    "corpus_noun_dtm = pd.read_pickle('./pickles/corpus1_dtm.pkl')\n",
    "corpus_noun_tim = pd.read_pickle('./pickles/corpus1_tim.pkl')\n",
    "corpus_na_dtm = pd.read_pickle('./pickles/corpus2_dtm.pkl')\n",
    "corpus_na_tim = pd.read_pickle('./pickles/corpus2_tim.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all vectorizers\n",
    "clean_corpus_cv = pickle.load(open('./pickles/corpus0_cv.pkl', 'rb'))\n",
    "clean_corpus_tf_idf = pickle.load(open('./pickles/corpus0_tf_idf.pkl','rb'))\n",
    "corpus_noun_cv = pickle.load(open('./pickles/corpus1_cv.pkl','rb'))\n",
    "corpus_noun_tf_idf = pickle.load(open('./pickles/corpus1_tf_idf.pkl','rb'))\n",
    "corpus_na_cv = pickle.load(open('./pickles/corpus2_cv.pkl','rb'))\n",
    "corpus_na_tf_idf = pickle.load(open('./pickles/corpus2_tf_idf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"bitch\" + 0.015*\"man\" + 0.014*\"mom\" + 0.009*\"harry\" + 0.008*\"gon\" + 0.008*\"car\" + 0.008*\"okay\" + 0.008*\"slipper\" + 0.007*\"real\" + 0.007*\"ima\"'),\n",
       " (1,\n",
       "  '0.016*\"black\" + 0.013*\"accent\" + 0.011*\"good\" + 0.009*\"white\" + 0.009*\"man\" + 0.008*\"hes\" + 0.006*\"trevor\" + 0.006*\"cat\" + 0.006*\"friends\" + 0.006*\"thing\"'),\n",
       " (2,\n",
       "  '0.012*\"pool\" + 0.012*\"phone\" + 0.008*\"woman\" + 0.008*\"thing\" + 0.008*\"house\" + 0.007*\"gon\" + 0.007*\"guy\" + 0.007*\"god\" + 0.007*\"man\" + 0.006*\"motherfucker\"'),\n",
       " (3,\n",
       "  '0.014*\"train\" + 0.010*\"new\" + 0.010*\"money\" + 0.009*\"god\" + 0.008*\"baby\" + 0.008*\"year\" + 0.007*\"chinese\" + 0.007*\"doors\" + 0.007*\"man\" + 0.006*\"kids\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus_lda, result1 = train_LDA_model(clean_corpus_dtm, clean_corpus_cv)\n",
    "clean_corpus_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'Amy Schumer'),\n",
       " (2, 'Arsenio Hall'),\n",
       " (3, 'Aziz Ansari'),\n",
       " (2, 'CHRIS ROCK'),\n",
       " (2, 'Chris Rock'),\n",
       " (3, 'Dave Chappelle'),\n",
       " (1, 'Hasan Minhaj'),\n",
       " (2, 'JACK WHITEHALL'),\n",
       " (0, 'JO KOY'),\n",
       " (1, 'Jimmy O. Yang'),\n",
       " (0, 'Jo Koy'),\n",
       " (1, 'Joe Rogan'),\n",
       " (0, 'Kevin Hart'),\n",
       " (1, 'MICHAEL CHE'),\n",
       " (0, 'Michael McIntyre'),\n",
       " (0, 'Mike Epps'),\n",
       " (1, 'Neal Brennan'),\n",
       " (3, 'Ronny Chieng'),\n",
       " (0, 'Russell Peters'),\n",
       " (2, 'Sebastian Maniscalco'),\n",
       " (1, 'Trevor Noah'),\n",
       " (3, 'Vir Das'),\n",
       " (0, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"phone\" + 0.002*\"im\" + 0.002*\"shit\" + 0.001*\"youre\" + 0.001*\"train\" + 0.001*\"cat\" + 0.001*\"baby\" + 0.001*\"time\" + 0.001*\"people\" + 0.001*\"right\"'),\n",
       " (1,\n",
       "  '0.002*\"black\" + 0.002*\"mom\" + 0.001*\"white\" + 0.001*\"dad\" + 0.001*\"people\" + 0.001*\"shit\" + 0.001*\"thats\" + 0.001*\"rights\" + 0.001*\"friends\" + 0.001*\"civil\"'),\n",
       " (2,\n",
       "  '0.002*\"russian\" + 0.001*\"sexy\" + 0.001*\"men\" + 0.001*\"im\" + 0.001*\"sign\" + 0.001*\"diarrhea\" + 0.001*\"jumper\" + 0.001*\"pool\" + 0.001*\"hotel\" + 0.001*\"active\"'),\n",
       " (3,\n",
       "  '0.002*\"slipper\" + 0.002*\"ethiopians\" + 0.001*\"accent\" + 0.001*\"josep\" + 0.001*\"keys\" + 0.001*\"money\" + 0.001*\"black\" + 0.001*\"sex\" + 0.001*\"yall\" + 0.001*\"man\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_corpus_lda, result2 = train_LDA_model(clean_corpus_tim, clean_corpus_tf_idf)\n",
    "clean_corpus_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Amy Schumer'),\n",
       " (0, 'Arsenio Hall'),\n",
       " (0, 'Aziz Ansari'),\n",
       " (1, 'CHRIS ROCK'),\n",
       " (0, 'Chris Rock'),\n",
       " (3, 'Dave Chappelle'),\n",
       " (1, 'Hasan Minhaj'),\n",
       " (2, 'JACK WHITEHALL'),\n",
       " (3, 'JO KOY'),\n",
       " (1, 'Jimmy O. Yang'),\n",
       " (1, 'Jo Koy'),\n",
       " (0, 'Joe Rogan'),\n",
       " (0, 'Kevin Hart'),\n",
       " (1, 'MICHAEL CHE'),\n",
       " (2, 'Michael McIntyre'),\n",
       " (3, 'Mike Epps'),\n",
       " (1, 'Neal Brennan'),\n",
       " (0, 'Ronny Chieng'),\n",
       " (2, 'Russell Peters'),\n",
       " (0, 'Sebastian Maniscalco'),\n",
       " (3, 'Trevor Noah'),\n",
       " (0, 'Vir Das'),\n",
       " (3, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"accent\" + 0.014*\"mom\" + 0.011*\"good\" + 0.010*\"black\" + 0.009*\"slipper\" + 0.007*\"trevor\" + 0.007*\"josep\" + 0.006*\"white\" + 0.006*\"hey\" + 0.006*\"dad\"'),\n",
       " (1,\n",
       "  '0.012*\"pool\" + 0.011*\"right\" + 0.011*\"train\" + 0.010*\"money\" + 0.009*\"new\" + 0.007*\"guy\" + 0.006*\"chinese\" + 0.006*\"doors\" + 0.006*\"okay\" + 0.006*\"fuck\"'),\n",
       " (2,\n",
       "  '0.014*\"bitch\" + 0.010*\"right\" + 0.008*\"fuck\" + 0.008*\"house\" + 0.008*\"okay\" + 0.007*\"oh\" + 0.007*\"good\" + 0.007*\"cause\" + 0.007*\"god\" + 0.007*\"harry\"'),\n",
       " (3,\n",
       "  '0.021*\"phone\" + 0.017*\"russian\" + 0.010*\"black\" + 0.009*\"yeah\" + 0.009*\"white\" + 0.007*\"friends\" + 0.006*\"new\" + 0.006*\"hey\" + 0.005*\"years\" + 0.004*\"motherfucker\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_noun_lda, result3 = train_LDA_model(corpus_noun_dtm, corpus_noun_cv)\n",
    "corpus_noun_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Amy Schumer'),\n",
       " (3, 'Arsenio Hall'),\n",
       " (0, 'Aziz Ansari'),\n",
       " (2, 'CHRIS ROCK'),\n",
       " (1, 'Chris Rock'),\n",
       " (3, 'Dave Chappelle'),\n",
       " (2, 'Hasan Minhaj'),\n",
       " (1, 'JACK WHITEHALL'),\n",
       " (0, 'JO KOY'),\n",
       " (0, 'Jimmy O. Yang'),\n",
       " (0, 'Jo Koy'),\n",
       " (2, 'Joe Rogan'),\n",
       " (2, 'Kevin Hart'),\n",
       " (1, 'MICHAEL CHE'),\n",
       " (2, 'Michael McIntyre'),\n",
       " (3, 'Mike Epps'),\n",
       " (3, 'Neal Brennan'),\n",
       " (1, 'Ronny Chieng'),\n",
       " (3, 'Russell Peters'),\n",
       " (1, 'Sebastian Maniscalco'),\n",
       " (0, 'Trevor Noah'),\n",
       " (2, 'Vir Das'),\n",
       " (2, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"shit\" + 0.002*\"phone\" + 0.002*\"mom\" + 0.002*\"im\" + 0.001*\"time\" + 0.001*\"woman\" + 0.001*\"people\" + 0.001*\"men\" + 0.001*\"money\" + 0.001*\"cat\"'),\n",
       " (1,\n",
       "  '0.002*\"russian\" + 0.002*\"slipper\" + 0.001*\"white\" + 0.001*\"josep\" + 0.001*\"black\" + 0.001*\"keys\" + 0.001*\"friends\" + 0.001*\"mistakes\" + 0.001*\"people\" + 0.001*\"house\"'),\n",
       " (2,\n",
       "  '0.002*\"ethiopians\" + 0.002*\"train\" + 0.001*\"asian\" + 0.001*\"baby\" + 0.001*\"im\" + 0.001*\"chinese\" + 0.001*\"porn\" + 0.001*\"ha\" + 0.001*\"doors\" + 0.001*\"thats\"'),\n",
       " (3,\n",
       "  '0.001*\"accent\" + 0.001*\"im\" + 0.001*\"birthday\" + 0.001*\"sign\" + 0.001*\"diarrhea\" + 0.001*\"trevor\" + 0.001*\"pool\" + 0.001*\"hotel\" + 0.001*\"active\" + 0.001*\"hes\"')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_noun_lda, result4 = train_LDA_model(corpus_noun_tim, corpus_noun_tf_idf)\n",
    "corpus_noun_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Amy Schumer'),\n",
       " (0, 'Arsenio Hall'),\n",
       " (2, 'Aziz Ansari'),\n",
       " (1, 'CHRIS ROCK'),\n",
       " (0, 'Chris Rock'),\n",
       " (0, 'Dave Chappelle'),\n",
       " (3, 'Hasan Minhaj'),\n",
       " (3, 'JACK WHITEHALL'),\n",
       " (1, 'JO KOY'),\n",
       " (2, 'Jimmy O. Yang'),\n",
       " (0, 'Jo Koy'),\n",
       " (0, 'Joe Rogan'),\n",
       " (0, 'Kevin Hart'),\n",
       " (0, 'MICHAEL CHE'),\n",
       " (0, 'Michael McIntyre'),\n",
       " (2, 'Mike Epps'),\n",
       " (1, 'Neal Brennan'),\n",
       " (2, 'Ronny Chieng'),\n",
       " (1, 'Russell Peters'),\n",
       " (0, 'Sebastian Maniscalco'),\n",
       " (3, 'Trevor Noah'),\n",
       " (0, 'Vir Das'),\n",
       " (0, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"train\" + 0.009*\"money\" + 0.009*\"new\" + 0.008*\"hes\" + 0.007*\"kids\" + 0.007*\"baby\" + 0.007*\"year\" + 0.007*\"way\" + 0.007*\"chinese\" + 0.007*\"doors\"'),\n",
       " (1,\n",
       "  '0.011*\"accent\" + 0.011*\"mom\" + 0.010*\"black\" + 0.008*\"phone\" + 0.007*\"fuck\" + 0.007*\"woman\" + 0.007*\"slipper\" + 0.006*\"white\" + 0.006*\"god\" + 0.006*\"yeah\"'),\n",
       " (2,\n",
       "  '0.019*\"bitch\" + 0.011*\"harry\" + 0.009*\"gon\" + 0.008*\"okay\" + 0.008*\"car\" + 0.008*\"house\" + 0.008*\"ima\" + 0.008*\"russian\" + 0.007*\"face\" + 0.007*\"cause\"'),\n",
       " (3,\n",
       "  '0.010*\"pool\" + 0.008*\"gon\" + 0.008*\"guy\" + 0.008*\"black\" + 0.007*\"years\" + 0.007*\"fuck\" + 0.006*\"ive\" + 0.006*\"men\" + 0.006*\"bandaids\" + 0.006*\"okay\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_na_lda, result5 = train_LDA_model(corpus_na_dtm, corpus_na_cv)\n",
    "corpus_na_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Amy Schumer'),\n",
       " (1, 'Arsenio Hall'),\n",
       " (0, 'Aziz Ansari'),\n",
       " (1, 'CHRIS ROCK'),\n",
       " (3, 'Chris Rock'),\n",
       " (3, 'Dave Chappelle'),\n",
       " (0, 'Hasan Minhaj'),\n",
       " (2, 'JACK WHITEHALL'),\n",
       " (1, 'JO KOY'),\n",
       " (1, 'Jimmy O. Yang'),\n",
       " (1, 'Jo Koy'),\n",
       " (1, 'Joe Rogan'),\n",
       " (2, 'Kevin Hart'),\n",
       " (3, 'MICHAEL CHE'),\n",
       " (3, 'Michael McIntyre'),\n",
       " (2, 'Mike Epps'),\n",
       " (1, 'Neal Brennan'),\n",
       " (0, 'Ronny Chieng'),\n",
       " (2, 'Russell Peters'),\n",
       " (3, 'Sebastian Maniscalco'),\n",
       " (1, 'Trevor Noah'),\n",
       " (1, 'Vir Das'),\n",
       " (2, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"phone\" + 0.001*\"accent\" + 0.001*\"birthday\" + 0.001*\"trevor\" + 0.001*\"im\" + 0.001*\"oh\" + 0.001*\"hes\" + 0.001*\"dad\" + 0.001*\"white\" + 0.001*\"black\"'),\n",
       " (1,\n",
       "  '0.002*\"money\" + 0.002*\"pool\" + 0.001*\"train\" + 0.001*\"im\" + 0.001*\"sexy\" + 0.001*\"chinese\" + 0.001*\"sex\" + 0.001*\"asian\" + 0.001*\"people\" + 0.001*\"men\"'),\n",
       " (2,\n",
       "  '0.002*\"mom\" + 0.002*\"russian\" + 0.002*\"slipper\" + 0.001*\"baby\" + 0.001*\"cat\" + 0.001*\"black\" + 0.001*\"shit\" + 0.001*\"civil\" + 0.001*\"rights\" + 0.001*\"josep\"'),\n",
       " (3,\n",
       "  '0.002*\"im\" + 0.001*\"shit\" + 0.001*\"religion\" + 0.001*\"ethiopians\" + 0.001*\"white\" + 0.001*\"fun\" + 0.001*\"god\" + 0.001*\"black\" + 0.001*\"bitch\" + 0.001*\"woman\"')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_na_lda, result6 = train_LDA_model(corpus_na_tim, corpus_na_tf_idf)\n",
    "corpus_na_lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'Amy Schumer'),\n",
       " (0, 'Arsenio Hall'),\n",
       " (2, 'Aziz Ansari'),\n",
       " (3, 'CHRIS ROCK'),\n",
       " (3, 'Chris Rock'),\n",
       " (2, 'Dave Chappelle'),\n",
       " (0, 'Hasan Minhaj'),\n",
       " (1, 'JACK WHITEHALL'),\n",
       " (2, 'JO KOY'),\n",
       " (1, 'Jimmy O. Yang'),\n",
       " (2, 'Jo Koy'),\n",
       " (2, 'Joe Rogan'),\n",
       " (3, 'Kevin Hart'),\n",
       " (2, 'MICHAEL CHE'),\n",
       " (1, 'Michael McIntyre'),\n",
       " (3, 'Mike Epps'),\n",
       " (3, 'Neal Brennan'),\n",
       " (1, 'Ronny Chieng'),\n",
       " (2, 'Russell Peters'),\n",
       " (1, 'Sebastian Maniscalco'),\n",
       " (0, 'Trevor Noah'),\n",
       " (3, 'Vir Das'),\n",
       " (1, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "group_df = pd.DataFrame(index=[0,1,2,3])\n",
    "for i, result in enumerate([result1, result2, result3, result4, result5, result6]):\n",
    "    group = {}\n",
    "    for r in result:\n",
    "        if r[0] in group:\n",
    "            group[r[0]].append(r[1])\n",
    "        else:\n",
    "            group[r[0]] = [r[1]]\n",
    "    group_df[f'result_{i+1}'] = group.values()\n",
    "    groups.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df.to_csv('group.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSA_model(data_matrix, vectorizer, num_topics=5):\n",
    "    # df --> sparse matrix --> gensim corpus\n",
    "    sparse_counts = scipy.sparse.csr_matrix(data_matrix)\n",
    "    gensim_corpus = matutils.Sparse2Corpus(sparse_counts)\n",
    "    id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "    lsi = LsiModel(gensim_corpus, num_topics=num_topics, id2word=id2word)\n",
    "    \n",
    "    corpus_transformed = lsi[gensim_corpus]\n",
    "    result = list(zip([max(ct, key=lambda x: x[1])[0] for ct in corpus_transformed], data_matrix.columns))\n",
    "    return lsi, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.241*\"im\" + 0.186*\"shit\" + 0.185*\"people\" + 0.149*\"black\" + 0.146*\"youre\" + 0.141*\"thats\" + 0.139*\"time\" + 0.139*\"man\" + 0.126*\"white\" + 0.119*\"money\"'),\n",
       " (1,\n",
       "  '0.424*\"black\" + 0.323*\"white\" + 0.198*\"friends\" + 0.163*\"accent\" + 0.157*\"civil\" + 0.148*\"people\" + -0.144*\"mom\" + 0.143*\"rights\" + 0.118*\"rules\" + -0.115*\"money\"'),\n",
       " (2,\n",
       "  '0.414*\"mom\" + 0.250*\"slipper\" + 0.184*\"josep\" + 0.175*\"dad\" + 0.171*\"keys\" + -0.161*\"religion\" + 0.150*\"foot\" + -0.135*\"fellas\" + -0.135*\"phone\" + -0.128*\"motherfucker\"'),\n",
       " (3,\n",
       "  '0.289*\"mom\" + -0.224*\"pool\" + 0.208*\"shit\" + 0.166*\"slipper\" + -0.166*\"im\" + 0.138*\"religion\" + 0.122*\"josep\" + 0.122*\"woman\" + 0.122*\"black\" + -0.121*\"sign\"'),\n",
       " (4,\n",
       "  '0.313*\"train\" + 0.259*\"money\" + -0.225*\"ethiopians\" + -0.201*\"phone\" + 0.190*\"chinese\" + 0.180*\"asian\" + 0.157*\"doors\" + -0.130*\"slipper\" + 0.125*\"doctors\" + 0.118*\"sex\"')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_na_lsa, res = train_LSA_model(corpus_na_tim, corpus_na_tf_idf)\n",
    "corpus_na_lsa.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Amy Schumer'),\n",
       " (0, 'Arsenio Hall'),\n",
       " (0, 'Aziz Ansari'),\n",
       " (0, 'CHRIS ROCK'),\n",
       " (0, 'Chris Rock'),\n",
       " (1, 'Dave Chappelle'),\n",
       " (0, 'Hasan Minhaj'),\n",
       " (0, 'JACK WHITEHALL'),\n",
       " (2, 'JO KOY'),\n",
       " (4, 'Jimmy O. Yang'),\n",
       " (2, 'Jo Koy'),\n",
       " (0, 'Joe Rogan'),\n",
       " (0, 'Kevin Hart'),\n",
       " (1, 'MICHAEL CHE'),\n",
       " (0, 'Michael McIntyre'),\n",
       " (0, 'Mike Epps'),\n",
       " (1, 'Neal Brennan'),\n",
       " (4, 'Ronny Chieng'),\n",
       " (0, 'Russell Peters'),\n",
       " (0, 'Sebastian Maniscalco'),\n",
       " (0, 'Trevor Noah'),\n",
       " (0, 'Vir Das'),\n",
       " (0, 'Whitney Cummings')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Input   : dictionary : Gensim dictionary\n",
    "              corpus : Gensim corpus\n",
    "              texts : List of input texts\n",
    "              stop : Max num of topics\n",
    "    purpose : Compute c_v coherence for various number of topics\n",
    "    Output  : model_list : List of LSA topic models\n",
    "              coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, stop, step):\n",
    "        # generate LSA model\n",
    "        model = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word = dictionary)  # train model\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(doc_clean,start, stop, step):\n",
    "    dictionary,doc_term_matrix=prepare_corpus(doc_clean)\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix,doc_clean,\n",
    "                                                            stop, start, step)\n",
    "    # Show graph\n",
    "    x = range(start, stop, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"coherence_values\"), loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
